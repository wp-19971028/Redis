# 用户访问
1. 通过客户端访问服务器
2. 服务器通过Nginx(负载均衡)平均分发请求给java服务
3. 装载数据到mysql集群 

# 离线 
1. 通过ETL工具采集数据到HDFS
    1. ETL常用工具(kettle sqoop)
2. hive清洗转换
3. 在hive统计分析
4. 导出数据到APP层的mysql
5. 通过展现工具展现
    1. 展现工具(帆软BI SuperSet)

# 实时
1. 通过flume,lua,Nifi 采集日志
2. 存储在kafka消息队列
3. 用spark flink Storm 清洗转换
4. 用spark flink Storm聚合运算
5. 由于过度依赖磁盘读写效率太低在清洗转换和聚合计算时用redis缓存
6. 导出数据到HDFS 或者 APP层的mysql
7. 通过展现工具展现



![离线和实时流程](./assets\离线和实时流程.png)